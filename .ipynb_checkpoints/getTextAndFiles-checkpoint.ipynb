{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os, csv\n",
    "import shutil\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from socket import error as SocketError\n",
    "import errno\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import httplib2, requests, contextlib\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from requests.auth import HTTPBasicAuth, HTTPDigestAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: csv file here\n",
    "micro_sample_cvs = \"micro-sample_MANUAL_Apr17.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_file(str, file_name):\n",
    "    \"\"\"This function writes a string str to a given file name\"\"\"\n",
    "    with open(file_name, \"a\") as text_file:\n",
    "        text_file.write(str)\n",
    "def save_json(file, school):\n",
    "    with open(file, 'wb') as outfile:\n",
    "#         json.dump(school, outfile)\n",
    "        pickle.dump(school, outfile)\n",
    "#want the obj back\n",
    "def get_obj_back(file):\n",
    "    with open(file,'rb') as f:\n",
    "        var = pickle.load(f)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check(url):\n",
    "    \"\"\" Helper function, check if url is a valid list <- our backup plan\n",
    "    This functions helps to check the url that has service unavailable issues\n",
    "    Since status code fails to check this.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        urlopen(url)\n",
    "        \n",
    "    except urllib.error.URLError:\n",
    "        print(url + \" :URLError\")\n",
    "        return False\n",
    "    except urllib.error.HTTPError:\n",
    "        print(url +' :HTTPError')\n",
    "        return False\n",
    "    except SocketError:\n",
    "        print(url + 'SocketError')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_url(url):\n",
    "    \"\"\"This functions uses the status code to determine if the link is valid. This resolves\n",
    "    the links that redirects and most cases of authentication problems\"\"\"\n",
    "    code = \"[no code collected]\"\n",
    "    if url == \"\":\n",
    "        return False\n",
    "    try:\n",
    "        r = requests.get(url, auth=HTTPDigestAuth('user', 'pass'), headers= {'User-Agent':\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"})\n",
    "        code = r.status_code\n",
    "        #backup plan for service unavailable issues\n",
    "        if code == 503:\n",
    "            return check(url)\n",
    "        if code < 400:\n",
    "            return True   \n",
    "    except:\n",
    "        pass\n",
    "    print(\"Encounter an invalid link: \" + str(url) +\" ---Error code: \" + str(code))\n",
    "    return False    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(micro_sample_cvs)\n",
    "school_urls = df[\"URL\"]\n",
    "school_names = df[\"School name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the links of a websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_children_links(url_parent, hostname, visited, depth):\n",
    "    \"\"\"This function recursively gets the children links of a given links\"\"\"\n",
    "    #we have gone through enough levels or visited this link already \n",
    "    if depth == 0 or url_parent in visited or not check_url(url_parent):\n",
    "        return set()\n",
    "    \n",
    "    #get the html page\n",
    "    #parse into a BS object\n",
    "    html_page = requests.get(url_parent, auth=HTTPDigestAuth('user', 'pass'), headers= {'User-Agent':\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"})\n",
    "    soup = BeautifulSoup(html_page.text)\n",
    "\n",
    "    #we visited url_parent, updated into the set\n",
    "    visited.add(url_parent)\n",
    "    \n",
    "    #now checking its children\n",
    "    for link in soup.findAll('a'):\n",
    "        #running recursively in a try-except block to prevent broken links break the code\n",
    "        try:\n",
    "            pattern = re.compile(\"((http|ftp)s?://.*?)\")\n",
    "            current_link = link.get('href')\n",
    "#             print(current_link)\n",
    "            if not pattern.match(current_link):\n",
    "                current_link = urljoin(url_parent, current_link)\n",
    "            \n",
    "            #check if the link is within the domain (hostname)\n",
    "            if hostname in current_link:\n",
    "#                 print(current_link)\n",
    "                #combine results from its children's links\n",
    "                get_children_links(current_link, hostname, visited, depth -1)\n",
    "        except:\n",
    "            pass\n",
    "    return visited\n",
    "#     print(count)\n",
    "\n",
    "def getLinks(url, depth):\n",
    "    text = set()\n",
    "    hostname = urlparse(url).hostname\n",
    "    return get_children_links(url, hostname, text, depth)\n",
    "#delete "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Runing test\n",
      "Here are all the links from: https://www.richland2.org/charterhigh/\n",
      "https://www.richland2.org/CharterHigh/About-Our-School/Calendar\n",
      "https://www.richland2.org/CharterHigh/School-Information/School-Board\n",
      "https://www.richland2.org/CharterHigh/\n",
      "https://www.richland2.org/CharterHigh/Careers\n",
      "https://www.richland2.org/CharterHigh/About-Us\n",
      "https://www.richland2.org/CharterHigh/School-Information\n",
      "https://www.richland2.org/CharterHigh/School-Information/Directions\n",
      "https://www.richland2.org/charterhigh/\n",
      "https://www.richland2.org/CharterHigh/News\n",
      "https://www.richland2.org/CharterHigh/School-Information/Graduation-2017\n",
      "https://www.richland2.org/charterhigh/news\n",
      "https://www.richland2.org/CharterHigh/School-Information/Frequently-Asked-Questions\n",
      "https://www.richland2.org/CharterHigh/Student-Registration\n",
      "https://www.richland2.org/CharterHigh/Contact-Us\n",
      "https://www.richland2.org/CharterHigh/News/We-re-Hiring-a-Principal\n",
      "https://www.richland2.org/CharterHigh/news\n",
      "https://www.richland2.org/CharterHigh/School-Information/Calendar\n",
      "https://www.richland2.org/CharterHigh/School-Information/School-Improvement-Council\n",
      "https://www.richland2.org/CharterHigh/News/Welcome-to-Our-New-Website!\n",
      "https://www.richland2.org/CharterHigh/School-Information/Lab-Hours\n",
      "https://www.richland2.org/charterhigh/About-Our-School/Calendar\n",
      "https://www.richland2.org\n",
      "https://www.richland2.org/accessibility.aspx\n",
      "https://www.richland2.org/CharterHigh/Special-Pages/Site-Translations\n",
      "There are 24 of them\n"
     ]
    }
   ],
   "source": [
    "# test on 1 url\n",
    "urls = getLinks(\"https://www.richland2.org/charterhigh/\", 5)\n",
    "count = 0\n",
    "print(\"Runing test\")\n",
    "print(\"Here are all the links from: \" + \"https://www.richland2.org/charterhigh/\" )\n",
    "for e in urls:\n",
    "    count += 1\n",
    "    print(e)\n",
    "print(\"There are \" + str(count)+ \" of them\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now run this method on 300 sites, save as dictionary and store it as a JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RICHLAND TWO CHARTER HIGH\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "POLK STATE COLLEGE COLLEGIATE HIGH SCHOOL\n"
     ]
    }
   ],
   "source": [
    "schools = dict()\n",
    "cap = len(school_names)\n",
    "# cap = 2\n",
    "for i in range(cap):\n",
    "    link, name = school_urls[i], school_names[i]\n",
    "    #sanity check make sure all links are valid\n",
    "    if not check_url(link):\n",
    "        print(\"Hey! \" + name + \" doesnt have a valid link! \" + link)\n",
    "    print(school_names[i])\n",
    "    #saving school names as keys and list of links as values\n",
    "    schools.update({name: list(getLinks(link, 4))})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_json(\"list_of_links\", schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RICHLAND TWO CHARTER HIGH has 24\n",
      "['https://www.richland2.org/accessibility.aspx', 'https://www.richland2.org/CharterHigh/About-Us', 'https://www.richland2.org/CharterHigh/School-Information/Directions', 'https://www.richland2.org/CharterHigh/news', 'https://www.richland2.org', 'https://www.richland2.org/CharterHigh/Careers', 'https://www.richland2.org/CharterHigh/', 'https://www.richland2.org/CharterHigh/School-Information/Graduation-2017', 'https://www.richland2.org/CharterHigh/About-Our-School/Calendar', 'https://www.richland2.org/charterhigh/news', 'https://www.richland2.org/charterhigh/About-Our-School/Calendar', 'https://www.richland2.org/CharterHigh/School-Information/Lab-Hours', 'https://www.richland2.org/CharterHigh/News/We-re-Hiring-a-Principal', 'https://www.richland2.org/CharterHigh/School-Information', 'https://www.richland2.org/CharterHigh/Special-Pages/Site-Translations', 'https://www.richland2.org/CharterHigh/Student-Registration', 'https://www.richland2.org/CharterHigh/Contact-Us', 'https://www.richland2.org/CharterHigh/School-Information/Calendar', 'https://www.richland2.org/charterhigh/', 'https://www.richland2.org/CharterHigh/School-Information/Frequently-Asked-Questions', 'https://www.richland2.org/CharterHigh/School-Information/School-Improvement-Council', 'https://www.richland2.org/CharterHigh/News/Welcome-to-Our-New-Website!', 'https://www.richland2.org/CharterHigh/News', 'https://www.richland2.org/CharterHigh/School-Information/School-Board']\n",
      "POLK STATE COLLEGE COLLEGIATE HIGH SCHOOL has 51\n",
      "['https://www.polk.edu/community/', 'https://www.polk.edu/people/department/lakeland-gateway-to-college-high-school/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/', 'https://www.polk.edu/equity', 'https://www.polk.edu/', 'https://www.polk.edu/news/father-bullying-victim-implores-polk-state-students-upstanders-remember-loved-beyond-belief/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/guidance/', 'https://www.polk.edu/news/polks-top-grads-gateway-salutatorian-found-academic-footing-gained-confidence/', 'https://www.polk.edu/lake-wales/', 'https://www.polk.edu/bartow/', 'https://www.polk.edu/sitemap/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/registration-information-washington-dc/', 'https://www.polk.edu/about/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/admission-information/', 'https://www.polk.edu/news/in/lakeland-gateway-to-college-high-school/', 'https://www.polk.edu/wp-content/uploads/LakelandFlyerGHS.pdf', 'https://www.polk.edu/news/in/lakeland-gateway-to-college-high-school', 'https://www.polk.edu/events/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/about-us/board-of-trustees/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/senior-portraits-class-2017/', 'https://www.polk.edu/student-life/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/clubs/', 'https://www.polk.edu/equity-diversity/', 'https://www.polk.edu/events/memorial-day-holiday-college-closed-4/', 'https://www.polk.edu/admission-aid/', 'https://www.polk.edu/privacy-policy/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/school-bus-transportation-2016-2017-school-year/', 'https://www.polk.edu/lakeland/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/bullying-information/', 'https://www.polk.edu/news/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/dearly-dismissal-days-2015-16/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/college-and-career/scholarship-opportunities-2016/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/college-and-career/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/parent-internet-viewer/', 'https://www.polk.edu/academics/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/textbook-return-spring-2016/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/college-and-career/financial-aid-application-information-2016/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/#skip-content', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/higher-reach-site/', 'https://www.polk.edu/locations/', 'https://www.polk.edu/news/polks-top-grads-gateway-valedictorian-tools-study-university-level/', 'https://www.polk.edu/disclaimer/', 'https://www.polk.edu/library-tlcc/', 'https://www.polk.edu/winter-haven/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/administration-staff/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/student-resources/', 'https://www.polk.edu/people/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/about-us/', 'https://www.polk.edu/events/classes-meet-today/', 'https://www.polk.edu/lakeland-gateway-to-college-high-school/alumni-information/']\n"
     ]
    }
   ],
   "source": [
    "school_list = get_obj_back(\"list_of_links\")\n",
    "for i in school_list:\n",
    "    print(i + \" has \" + str(len(school_list[i])) )\n",
    "    print(school_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get all the html text by runing requests to get all the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since we all have a list of the links alreay, now we are ready to create folders to store these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_images(url):\n",
    "\n",
    "    html_page = requests.get(url, auth=HTTPDigestAuth('user', 'pass'), headers= {'User-Agent':\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"})\n",
    "    soup = BeautifulSoup(html_page.text, \"lxml\")\n",
    "    images = set()\n",
    "    # getting the links of the images\n",
    "    for link in soup.find_all('img'):\n",
    "        try:\n",
    "            image = link.get(\"src\")          \n",
    "            pattern = re.compile(\"((http|ftp)s?://.*?)\")\n",
    "            #relative link, need to append to parent's link to that the correct link\n",
    "            if not pattern.match(image):\n",
    "                image = urljoin(url, image)\n",
    "            images.add(image)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return images  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://1.cdn.edl.io/MdD7AmfcxcBFnrzZAUPjnNkl03XISc3hupv1Wh2TtLvb2kOB.jpg\n",
      "http://www.wattslearningcenter.org/pics/bullet_arrow.gif\n",
      "http://counter.edlio.com/count.jsp?rn=5242&i=WLCD-D&s=/index.jsp\n",
      "http://www.wattslearningcenter.org/pics/topnav_hover.png\n",
      "http://www.wattslearningcenter.org/rotating_images/7042/7042_47_1000_0_100.jpg\n",
      "http://www.wattslearningcenter.org/pics/edlio.png\n"
     ]
    }
   ],
   "source": [
    "r  = get_images(\"http://www.wattslearningcenter.org/#content_main\")\n",
    "for i in r:\n",
    "    print(i)\n",
    "#might need to check on size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pdfs(url):\n",
    "\n",
    "    html_page = requests.get(url, auth=HTTPDigestAuth('user', 'pass'), headers= {'User-Agent':\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"})\n",
    "    soup = BeautifulSoup(html_page.text, \"lxml\")\n",
    "    pdfs = set()\n",
    "    # getting the links of the images\n",
    "    for link in soup.findAll('a'):\n",
    "        try:\n",
    "            pdf = link.get('href')          \n",
    "            pattern = re.compile(\"((http|ftp)s?://.*?)\")\n",
    "            #relative link, need to append to parent's link to that the correct link\n",
    "            if not pattern.match(pdf):\n",
    "                pdf = urljoin(url, pdf)\n",
    "                \n",
    "            if(pdf.endswith(\".pdf\")):\n",
    "                pdfs.add(pdf)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return pdfs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw10/prob10.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/proj/controls-primer.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/linalg/EigenvaluesEigenvectors.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw0/prob0.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/linalg/BasisAndDiagonalization.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture13A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw2/prob2.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw9/prob9.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture6A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture0A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/midterm1_sol.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/Voltage.pdf\n",
      "https://www.ling.ohio-state.edu/~kbaker/pubs/Singular_Value_Decomposition_Tutorial.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lab/oscilloscope-cheatsheet.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lab/outline.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/VoltageAndCurrentDividers.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw1/sol1.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture8A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw4/prob4.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture12B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/proj/proj-grading.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/proj/proj-deliv.pdf\n",
      "http://terpconnect.umd.edu/~jzsimon/enee222/ref/enee241text0708.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw4/sol4.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture3B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture1A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw1/prob1.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture5A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture11B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture9B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw2/sol2.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw5/prob5.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/Current.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/thevenin.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture11A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture5B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture6B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture1B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture0B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture2A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/ResistorsInSeriesAndParallel.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture3A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw3/sol3.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw3/prob3.pdf\n",
      "http://math.mit.edu/~gs/linearalgebra/linearalgebra5_7-1.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw9/sol9.pdf\n",
      "https://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture7A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/Charge.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture2B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture4B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture8B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw5/sol5.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw0/sol0.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/midterm2_sol.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/Kirchoff.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/midterm1.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw7/sol7.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw11/prob11.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/midterm2.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture9A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw7/prob7.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw10/sol10.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture7B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture12A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw6/prob6.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw6/sol6.pdf\n"
     ]
    }
   ],
   "source": [
    "m  = get_pdfs(\"http://inst.eecs.berkeley.edu/~ee16b/sp17/\")\n",
    "for i in m:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here is the fun part. We will run our code to get everything, from text, images, and pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_folder_name (k, name):\n",
    "    \"\"\"Format a folder nicely for easy access\"\"\"\n",
    "    if k < 10: # Add two zeros to the folder name if k is less than 10 (for ease of organizing the output folders)\n",
    "        dirname = \"00\" + str(k) + \" \" + name\n",
    "    elif k < 100: # Add one zero if k is less than 100\n",
    "        dirname = \"0\" + str(k) + \" \" + name\n",
    "    else: # Add nothing if k>100\n",
    "        dirname = str(k) + \" \" + name\n",
    "    return dirname\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_master(school_list, parent_folder):\n",
    "    \"\"\"webscrap links and print output to appropriate folders\"\"\"\n",
    "    #navigate to parent folder\n",
    "    k = 0\n",
    "    os.chdir(parent_folder)\n",
    "    for school in school_list:\n",
    "        # create dir my_folder if it doesn't exist yet\n",
    "        os.chdir(parent_folder)\n",
    "        curr_folder_name = format_folder_name(k, school)\n",
    "        if not os.path.exists(curr_folder_name):\n",
    "            os.makedirs(curr_folder_name)\n",
    "        #navigate to the correct folder, ready to scrap\n",
    "        os.chdir(curr_folder_name)\n",
    "        #scrap link to get html content\n",
    "        for url in school_list[school]:\n",
    "            html_page = requests.get(url, auth=HTTPDigestAuth('user', 'pass'), headers= {'User-Agent':\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"})\n",
    "            soup = BeautifulSoup(html_page.text)\n",
    "            try:\n",
    "                file_name = re.sub('[^A-Za-z0-9]+', '', soup.title.string) + \".txt\"\n",
    "            except:\n",
    "                file_name = \"no name\" + str(i) + \".txt\"\n",
    "                i += 1\n",
    "            write_file(\"link:\" + str(url)+ \"\\n\",file_name )\n",
    "            write_file(\"----------------------------------------------\\n\", file_name)\n",
    "            write_file(str(soup.prettify()), file_name)\n",
    "        \n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6d0dd04f3310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparent_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/anhnguyen/Desktop/research/scraping_Python/python requests results\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_master\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschool_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-dbef02c9bb4b>\u001b[0m in \u001b[0;36mrun_master\u001b[0;34m(school_list, parent_folder)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mhtml_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHTTPDigestAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_page\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^A-Za-z0-9]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "parent_folder = \"/Users/anhnguyen/Desktop/research/scraping_Python/python requests results\"\n",
    "run_master(school_list, parent_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
