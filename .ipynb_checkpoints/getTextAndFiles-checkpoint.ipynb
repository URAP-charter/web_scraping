{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os, csv\n",
    "import shutil\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from socket import error as SocketError\n",
    "import errno\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import httplib2, requests, contextlib\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from requests.auth import HTTPBasicAuth, HTTPDigestAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: csv file here\n",
    "micro_sample_cvs = \"micro-sample_MANUAL_Apr17.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_file(str, file_name):\n",
    "    \"\"\"This function writes a string str to a given file name\"\"\"\n",
    "    with open(file_name, \"a\") as text_file:\n",
    "        text_file.write(str)\n",
    "def save_json(file, school):\n",
    "    with open(file, 'wb') as outfile:\n",
    "#         json.dump(school, outfile)\n",
    "        pickle.dump(school, outfile)\n",
    "#want the obj back\n",
    "def get_obj_back(file):\n",
    "    with open(file,'rb') as f:\n",
    "        var = pickle.load(f)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check(url):\n",
    "    \"\"\" Helper function, check if url is a valid list <- our backup plan\n",
    "    This functions helps to check the url that has service unavailable issues\n",
    "    Since status code fails to check this.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        urlopen(url)\n",
    "        \n",
    "    except urllib.error.URLError:\n",
    "        print(url + \" :URLError\")\n",
    "        return False\n",
    "    except urllib.error.HTTPError:\n",
    "        print(url +' :HTTPError')\n",
    "        return False\n",
    "    except SocketError:\n",
    "        print(url + 'SocketError')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_url(url):\n",
    "    \"\"\"This functions uses the status code to determine if the link is valid. This resolves\n",
    "    the links that redirects and most cases of authentication problems\"\"\"\n",
    "    code = \"[no code collected]\"\n",
    "    if url == \"\":\n",
    "        return False\n",
    "    try:\n",
    "        r = requests.get(url, auth=HTTPDigestAuth('user', 'pass'), headers= {'User-Agent':\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"})\n",
    "        code = r.status_code\n",
    "        #backup plan for service unavailable issues\n",
    "        if code == 503:\n",
    "            return check(url)\n",
    "        if code < 400:\n",
    "            return True   \n",
    "    except:\n",
    "        pass\n",
    "    print(\"Encounter an invalid link: \" + str(url) +\" ---Error code: \" + str(code))\n",
    "    return False    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(micro_sample_cvs)\n",
    "school_urls = df[\"URL\"]\n",
    "school_names = df[\"School name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the links of a websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_children_links(url_parent, hostname, visited, depth):\n",
    "    \"\"\"This function recursively gets the children links of a given links\"\"\"\n",
    "    #we have gone through enough levels or visited this link already \n",
    "    if depth == 0 or url_parent in visited or not check_url(url_parent):\n",
    "        return set()\n",
    "    \n",
    "    #get the html page\n",
    "    #parse into a BS object\n",
    "    html_page = requests.get(url_parent, auth=HTTPDigestAuth('user', 'pass'), headers= {'User-Agent':\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"})\n",
    "    soup = BeautifulSoup(html_page.text)\n",
    "\n",
    "    #we visited url_parent, updated into the set\n",
    "    visited.add(url_parent)\n",
    "    \n",
    "    #now checking its children\n",
    "    for link in soup.findAll('a'):\n",
    "        #running recursively in a try-except block to prevent broken links break the code\n",
    "        try:\n",
    "            pattern = re.compile(\"((http|ftp)s?://.*?)\")\n",
    "            current_link = link.get('href')\n",
    "#             print(current_link)\n",
    "            if not pattern.match(current_link):\n",
    "                current_link = urljoin(url_parent, current_link)\n",
    "            \n",
    "            #check if the link is within the domain (hostname)\n",
    "            if hostname in current_link:\n",
    "#                 print(current_link)\n",
    "                #combine results from its children's links\n",
    "                get_children_links(current_link, hostname, visited, depth -1)\n",
    "        except:\n",
    "            pass\n",
    "    return visited\n",
    "#     print(count)\n",
    "\n",
    "def getLinks(url, depth):\n",
    "    text = set()\n",
    "    hostname = urlparse(url).hostname\n",
    "    return get_children_links(url, hostname, text, depth)\n",
    "#delete "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Runing test\n",
      "Here are all the links from: https://www.richland2.org/charterhigh/\n",
      "https://www.richland2.org/CharterHigh/About-Our-School/Calendar\n",
      "https://www.richland2.org/CharterHigh/School-Information/School-Board\n",
      "https://www.richland2.org/CharterHigh/\n",
      "https://www.richland2.org/CharterHigh/Careers\n",
      "https://www.richland2.org/CharterHigh/About-Us\n",
      "https://www.richland2.org/CharterHigh/School-Information\n",
      "https://www.richland2.org/CharterHigh/School-Information/Directions\n",
      "https://www.richland2.org/charterhigh/\n",
      "https://www.richland2.org/CharterHigh/News\n",
      "https://www.richland2.org/CharterHigh/School-Information/Graduation-2017\n",
      "https://www.richland2.org/charterhigh/news\n",
      "https://www.richland2.org/CharterHigh/School-Information/Frequently-Asked-Questions\n",
      "https://www.richland2.org/CharterHigh/Student-Registration\n",
      "https://www.richland2.org/CharterHigh/Contact-Us\n",
      "https://www.richland2.org/CharterHigh/News/We-re-Hiring-a-Principal\n",
      "https://www.richland2.org/CharterHigh/news\n",
      "https://www.richland2.org/CharterHigh/School-Information/Calendar\n",
      "https://www.richland2.org/CharterHigh/School-Information/School-Improvement-Council\n",
      "https://www.richland2.org/CharterHigh/News/Welcome-to-Our-New-Website!\n",
      "https://www.richland2.org/CharterHigh/School-Information/Lab-Hours\n",
      "https://www.richland2.org/charterhigh/About-Our-School/Calendar\n",
      "https://www.richland2.org\n",
      "https://www.richland2.org/accessibility.aspx\n",
      "https://www.richland2.org/CharterHigh/Special-Pages/Site-Translations\n",
      "There are 24 of them\n"
     ]
    }
   ],
   "source": [
    "# test on 1 url\n",
    "urls = getLinks(\"https://www.richland2.org/charterhigh/\", 5)\n",
    "count = 0\n",
    "print(\"Runing test\")\n",
    "print(\"Here are all the links from: \" + \"https://www.richland2.org/charterhigh/\" )\n",
    "for e in urls:\n",
    "    count += 1\n",
    "    print(e)\n",
    "print(\"There are \" + str(count)+ \" of them\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now run this method on 300 sites, save as dictionary and store it as a JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RICHLAND TWO CHARTER HIGH\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "Encounter an invalid link: https://www.richland2.org/~ ---Error code: 404\n",
      "POLK STATE COLLEGE COLLEGIATE HIGH SCHOOL\n"
     ]
    }
   ],
   "source": [
    "schools = dict()\n",
    "cap = len(school_names)\n",
    "# cap = 2\n",
    "for i in range(cap):\n",
    "    link, name = school_urls[i], school_names[i]\n",
    "    #sanity check make sure all links are valid\n",
    "    if not check_url(link):\n",
    "        print(\"Hey! \" + name + \" doesnt have a valid link! \" + link)\n",
    "    print(school_names[i])\n",
    "    schools.update({name: list(getLinks(link, 4))})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_json(\"list_of_links\", schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLK STATE COLLEGE COLLEGIATE HIGH SCHOOLhas 51\n",
      "RICHLAND TWO CHARTER HIGHhas 24\n"
     ]
    }
   ],
   "source": [
    "school_list = get_obj_back(\"list_of_links\")\n",
    "for i in school_list:\n",
    "    print(i + \" has \" + str(len(school_list[i])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_images(url):\n",
    "\n",
    "    html_page = requests.get(url, auth=HTTPDigestAuth('user', 'pass'), headers= {'User-Agent':\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"})\n",
    "    soup = BeautifulSoup(html_page.text, \"lxml\")\n",
    "    images = set()\n",
    "    # getting the links of the images\n",
    "    for link in soup.find_all('img'):\n",
    "        try:\n",
    "            image = link.get(\"src\")          \n",
    "            pattern = re.compile(\"((http|ftp)s?://.*?)\")\n",
    "            #relative link, need to append to parent's link to that the correct link\n",
    "            if not pattern.match(image):\n",
    "                image = urljoin(url, image)\n",
    "            images.add(image)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return images  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://1.cdn.edl.io/MdD7AmfcxcBFnrzZAUPjnNkl03XISc3hupv1Wh2TtLvb2kOB.jpg\n",
      "http://www.wattslearningcenter.org/pics/bullet_arrow.gif\n",
      "http://counter.edlio.com/count.jsp?rn=5242&i=WLCD-D&s=/index.jsp\n",
      "http://www.wattslearningcenter.org/pics/topnav_hover.png\n",
      "http://www.wattslearningcenter.org/rotating_images/7042/7042_47_1000_0_100.jpg\n",
      "http://www.wattslearningcenter.org/pics/edlio.png\n"
     ]
    }
   ],
   "source": [
    "r  = get_images(\"http://www.wattslearningcenter.org/#content_main\")\n",
    "for i in r:\n",
    "    print(i)\n",
    "#might need to check on size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pdfs(url):\n",
    "\n",
    "    html_page = requests.get(url, auth=HTTPDigestAuth('user', 'pass'), headers= {'User-Agent':\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\"})\n",
    "    soup = BeautifulSoup(html_page.text, \"lxml\")\n",
    "    pdfs = set()\n",
    "    # getting the links of the images\n",
    "    for link in soup.findAll('a'):\n",
    "        try:\n",
    "            pdf = link.get('href')          \n",
    "            pattern = re.compile(\"((http|ftp)s?://.*?)\")\n",
    "            #relative link, need to append to parent's link to that the correct link\n",
    "            if not pattern.match(pdf):\n",
    "                pdf = urljoin(url, pdf)\n",
    "                \n",
    "            if(pdf.endswith(\".pdf\")):\n",
    "                pdfs.add(pdf)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return pdfs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw10/prob10.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/proj/controls-primer.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/linalg/EigenvaluesEigenvectors.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw0/prob0.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/linalg/BasisAndDiagonalization.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture13A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw2/prob2.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw9/prob9.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture6A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture0A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/midterm1_sol.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/Voltage.pdf\n",
      "https://www.ling.ohio-state.edu/~kbaker/pubs/Singular_Value_Decomposition_Tutorial.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lab/oscilloscope-cheatsheet.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lab/outline.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/VoltageAndCurrentDividers.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw1/sol1.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture8A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw4/prob4.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture12B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/proj/proj-grading.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/proj/proj-deliv.pdf\n",
      "http://terpconnect.umd.edu/~jzsimon/enee222/ref/enee241text0708.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw4/sol4.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture3B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture1A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw1/prob1.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture5A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture11B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture9B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw2/sol2.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw5/prob5.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/Current.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/thevenin.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture11A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture5B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture6B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture1B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture0B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture2A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/ResistorsInSeriesAndParallel.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture3A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw3/sol3.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw3/prob3.pdf\n",
      "http://math.mit.edu/~gs/linearalgebra/linearalgebra5_7-1.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw9/sol9.pdf\n",
      "https://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture7A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/Charge.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture2B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture4B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture8B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw5/sol5.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw0/sol0.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/midterm2_sol.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/circuits/Kirchoff.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/midterm1.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw7/sol7.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw11/prob11.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/note/midterm2.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture9A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw7/prob7.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw10/sol10.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture7B.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/lec/Lecture12A.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw6/prob6.pdf\n",
      "http://inst.eecs.berkeley.edu/~ee16b/sp17/hw/hw6/sol6.pdf\n"
     ]
    }
   ],
   "source": [
    "m  = get_pdfs(\"http://inst.eecs.berkeley.edu/~ee16b/sp17/\")\n",
    "for i in m:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
